# Fase 20 â€” Meta-Learning Loop (Plan de ImplementaciÃ³n)

## ğŸ¯ Objetivo
Implementar un controlador de meta-aprendizaje ligero que observe pÃ©rdidas, activaciones y atenciÃ³n para ajustar dinÃ¡micamente:

- **Learning rate** del optimizador principal
- **Frecuencia de consolidaciÃ³n** (sleep cycles) del `MemoryReplaySystem`
- **Peso de atenciÃ³n global** o foco cognitivo

La meta es lograr que el sistema se autorregule sin entrenar un modelo aparte.

## ğŸ§± Componentes Propuestos

```
src/core/
 â”œâ”€ meta/
 â”‚   â”œâ”€ rules.py              # Estrategias adaptativas (LR, foco, sueÃ±o)
 â”‚   â””â”€ meta_controller.py    # Controlador que aplica las reglas
 â”œâ”€ training/
 â”‚   â””â”€ trainer.py            # Ajustes menores para exponer lr dinÃ¡mico
examples/
 â””â”€ meta_learning_demo.py     # Demo integrando el meta-loop
```

### 1. `src/core/meta/rules.py`
Funciones puras que reciben mÃ©tricas y devuelven hiperparÃ¡metros ajustados. Primera iteraciÃ³n:

- `adaptive_lr(prev_loss, curr_loss, lr)`
- `adaptive_focus(att_mean, focus)`
- `adaptive_sleep(loss_trend, base_interval)`

Agregar clips para mantener los valores dentro de rangos razonables.

### 2. `src/core/meta/meta_controller.py`
Clase `MetaLearningController` que:

1. Guarda referencias al `GraphTrainer`, `MemoryReplaySystem` y `CognitiveMonitor`.
2. Registra estado actual (`lr`, `focus`, `sleep_interval`, `prev_loss`).
3. Expone `observe_and_adjust(epoch, curr_loss)` para aplicar las reglas.
4. Expone `maybe_sleep(epoch)` para ejecutar `sleep_and_replay()` cuando corresponde.
5. Emite logs con nivel `META` usando el monitor para fÃ¡cil depuraciÃ³n.

### 3. Demo `examples/meta_learning_demo.py`
Probar con un `CognitiveGraphHybrid` sencillo (input â†’ reasoner â†’ decision). Bucle de ~60 Ã©pocas:

1. Ejecutar `train_step` con dataset XOR.
2. Registrar pÃ©rdida en el monitor.
3. Invocar el meta-controller.
4. Mostrar mÃ©tricas finales (`lr`, `focus`, `sleep_interval`).

## âœ… Entregables Esperados

- Nuevos mÃ³dulos `src/core/meta/*` con tests bÃ¡sicos (al menos validaciÃ³n de clips y ajustes).
- Demo funcional que imprima los ajustes META y demuestre consolidaciÃ³n adaptativa.
- ActualizaciÃ³n de `docs/proyecto.md` para reflejar la Fase 20 una vez completada.
- (Opcional) Persistir `lr`, `focus`, `sleep_interval` en el snapshot para el dashboard.

## ğŸ—“ï¸ Plan de Trabajo (Siguiente SesiÃ³n)

1. Crear paquete `core.meta` y definir reglas adaptativas con cobertura de tests mÃ­nimos.
2. Implementar `MetaLearningController` y asegurar compatibilidad con `GraphTrainer`/`MemoryReplaySystem`.
3. Desarrollar `meta_learning_demo.py` con dataset pequeÃ±o (XOR) y logs demostrativos.
4. (Si da el tiempo) Integrar mÃ©tricas META en `dashboard_state.json` para futura visualizaciÃ³n.

Listo para arrancar maÃ±ana con esta guÃ­a.
