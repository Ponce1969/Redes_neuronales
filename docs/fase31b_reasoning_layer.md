# üß† Fase 31-B: Cognitive Reasoning Layer

## üìã Descripci√≥n

La **Cognitive Reasoning Layer** introduce un controlador inteligente que decide qu√© bloques del grafo cognitivo activar (y con qu√© intensidad) antes de ejecutar el grafo. Esto permite:

- **Rutas cognitivas selectivas**: El Reasoner decide din√°micamente qu√© caminos computacionales seguir
- **Eficiencia adaptativa**: Bloques irrelevantes pueden ser desactivados o atenuados
- **Razonamiento expl√≠cito**: Las decisiones del Reasoner son inspeccionables y visualizables

## üèóÔ∏è Arquitectura

### Reasoner (MLP en NumPy)

```python
Input: z_plan por bloque (concatenados)
  ‚Üì
Hidden Layer (tanh)
  ‚Üì
Output Layer (n_blocks logits)
  ‚Üì
Gating Strategy (softmax/topk/threshold)
  ‚Üì
Gates aplicados a cada bloque
```

### Integraci√≥n con CognitiveGraphHybrid

```python
# Forward normal
outputs = graph.forward(inputs)

# Forward con control selectivo
outputs = graph.forward_with_reasoner(inputs, reasoner, mode="softmax")
```

## üöÄ Uso B√°sico

### 1. Crear un Reasoner

```python
from core.reasoning import Reasoner

# n_inputs: tama√±o concatenado de z_plan por bloque
# n_hidden: neuronas en capa oculta
# n_blocks: n√∫mero de bloques en el grafo
reasoner = Reasoner(n_inputs=32, n_hidden=64, n_blocks=4, seed=42)
```

### 2. Ejecutar Inferencia Selectiva

```python
# Forward normal para computar planes latentes
_ = graph.forward({"sensor": [0.5, 0.5]})

# Forward con reasoner (decide gates)
outputs = graph.forward_with_reasoner(
    {"sensor": [0.5, 0.5]},
    reasoner,
    mode="softmax"  # o "topk", "threshold"
)

# Ver gates aplicados
print(graph.last_gates)
# {'sensor': 0.25, 'planner': 0.30, 'memory': 0.20, 'decision': 0.25}
```

### 3. Modos de Gating

#### Softmax (continuo)
```python
gates = reasoner.decide(z_list, mode="softmax", temp=1.0)
# Distribuci√≥n suave: todos los bloques reciben alg√∫n peso
```

#### Top-K (sparse)
```python
gates = reasoner.decide(z_list, mode="topk", top_k=2)
# Solo los top-2 bloques se activan, resto = 0
```

#### Threshold (adaptativo)
```python
gates = reasoner.decide(z_list, mode="threshold")
# Solo bloques con logit > 0.1 se activan
```

## üß¨ Entrenamiento Evolutivo

### Estrategia Simple (1+Œª)

```python
from core.reasoning import evolve_reasoner_on_task, evaluate_reasoner

# Dataset XOR
X = np.array([[0,0], [0,1], [1,0], [1,1]], dtype=np.float32)
Y = np.array([0, 1, 1, 0], dtype=np.float32)

# Evolucionar Reasoner
reasoner_evolved, loss_history = evolve_reasoner_on_task(
    graph=graph,
    base_reasoner=reasoner,
    X=X,
    Y=Y,
    generations=50,
    pop_size=10,
    mutation_scale=0.03,
    verbose=True
)

# Evaluar mejora
initial_loss = loss_history[0]
final_loss = loss_history[-1]
improvement = ((initial_loss - final_loss) / initial_loss) * 100
print(f"Mejora: {improvement:.2f}%")
```

### Funcionamiento

1. **Generaci√≥n**: Crea `pop_size` mutantes del mejor Reasoner
2. **Evaluaci√≥n**: Ejecuta cada mutante en el dataset y calcula MSE
3. **Selecci√≥n**: Si alg√∫n mutante mejora, reemplaza al padre
4. **Repetir**: Por N generaciones

**Ventaja**: No requiere autograd, compatible con tu arquitectura actual.

## üìä An√°lisis y Visualizaci√≥n

### Extraer Historial de Gates

```python
from core.reasoning import extract_gates_history

history = extract_gates_history(graph, reasoner, X, mode="softmax")

# history[i] = {'sensor': 0.25, 'planner': 0.30, ...} para X[i]
```

### Visualizaci√≥n en Dashboard

```python
# Los gates se guardan autom√°ticamente en graph.last_gates
# Puedes colorear nodos en PyG/Plotly seg√∫n gate:

import matplotlib.pyplot as plt
import networkx as nx

gates = graph.last_gates
colors = [gates[name] for name in graph.blocks.keys()]

nx.draw(G, node_color=colors, cmap='coolwarm', vmin=0, vmax=1)
plt.colorbar(label='Gate Activation')
```

## üîß Persistencia

### Guardar Reasoner Entrenado

```python
import numpy as np

# Guardar
state = reasoner.state_dict()
np.savez_compressed('reasoner_weights.npz', **state)

# Cargar
loaded = np.load('reasoner_weights.npz')
reasoner.load_state_dict(dict(loaded))
```

## üìà Ejemplos

### Demo B√°sico
```bash
PYTHONPATH=src uv run python examples/cognitive_reasoning_demo.py
```

Muestra:
- Inferencia con diferentes modos de gating
- Comparaci√≥n forward normal vs reasoner
- Gates aplicados por bloque

### Demo Evolutivo
```bash
PYTHONPATH=src uv run python examples/cognitive_reasoning_evolution_demo.py
```

Muestra:
- Entrenamiento evolutivo en XOR
- Curva de aprendizaje
- An√°lisis de gates aplicados
- Comparaci√≥n predicciones antes/despu√©s

## üß™ Tests

```bash
PYTHONPATH=src uv run pytest tests/test_reasoning.py -v
```

Cubre:
- Inicializaci√≥n y configuraci√≥n
- Modos de gating (softmax, topk, threshold)
- Mutaci√≥n y serializaci√≥n
- Integraci√≥n con CognitiveGraphHybrid
- Entrenamiento evolutivo

## üéØ Compatibilidad

El Reasoner es compatible con:

- ‚úÖ **CognitiveBlock** (cl√°sico con Value)
- ‚úÖ **TRM_ACT_Block** (recursivo con Tensor)
- ‚úÖ **LatentPlannerBlock** (con z_plan expl√≠cito)
- ‚úÖ **ProjectionLayer** (AutoAlign)
- ‚úÖ **AttentionRouter** (atenci√≥n cognitiva)
- ‚úÖ **CognitiveMonitor** (tracking de activaciones)

## üîÆ Pr√≥ximos Pasos

### A Corto Plazo

1. **Integraci√≥n con Dashboard**: Visualizar gates en tiempo real
   - Colorear nodos por gate en `dashboard_pyg_interactive.py`
   - A√±adir heatmap temporal de gates en Streamlit

2. **Tracking en Monitor**: Registrar decisiones del Reasoner
   ```python
   monitor.track_gates(epoch, graph.last_gates)
   ```

3. **Multi-Objetivo**: Evolucionar considerando loss + eficiencia
   ```python
   fitness = loss + lambda * mean_gate  # Penalizar activaci√≥n total
   ```

### A Largo Plazo

4. **Migraci√≥n a PyTorch**: Reasoner diferenciable end-to-end
   ```python
   class TorchReasoner(nn.Module):
       # Backprop directo sobre gates
   ```

5. **Meta-Learning**: Reasoner aprende a aprender
   - Entrenar en m√∫ltiples tareas
   - Transfer learning entre grafos

6. **Reasoner Jer√°rquico**: Control multi-nivel
   - Meta-Reasoner decide qu√© sub-grafos activar
   - Sub-Reasoners controlan bloques individuales

## üìö Archivos Implementados

```
src/core/reasoning/
‚îú‚îÄ‚îÄ __init__.py              # Exportaciones del m√≥dulo
‚îú‚îÄ‚îÄ reasoner.py              # Clase Reasoner (MLP + mutaci√≥n)
‚îî‚îÄ‚îÄ training.py              # Utilidades de entrenamiento evolutivo

examples/
‚îú‚îÄ‚îÄ cognitive_reasoning_demo.py           # Demo b√°sico
‚îî‚îÄ‚îÄ cognitive_reasoning_evolution_demo.py # Demo con entrenamiento

tests/
‚îî‚îÄ‚îÄ test_reasoning.py        # Suite completa de tests

docs/
‚îî‚îÄ‚îÄ fase31b_reasoning_layer.md  # Esta documentaci√≥n
```

## üí° Tips de Uso

### 1. Dimensionamiento del Reasoner

```python
# Rule of thumb:
n_inputs = max_plan_dim * n_blocks  # Con padding autom√°tico
n_hidden = 2 * n_inputs            # Capacidad expresiva
```

### 2. Escala de Mutaci√≥n

```python
# Exploraci√≥n agresiva: scale=0.05
# Refinamiento fino: scale=0.01
# Balance recomendado: scale=0.03
```

### 3. Poblaci√≥n Evolutiva

```python
# Pocos bloques (3-5): pop_size=8
# Grafos medianos (6-10): pop_size=12
# Grafos grandes (>10): pop_size=16
```

### 4. Debugging

```python
# Verificar gates suman ~1.0 en softmax
gates = reasoner.decide(z_list, mode="softmax")
print(f"Sum: {sum(gates.values())}")  # Debe ser ‚âà 1.0

# Verificar activaci√≥n real de bloques
for name, block in graph.blocks.items():
    print(f"{name}: act={block.last_activation:.4f}, gate={graph.last_gates[name]:.4f}")
```

## üéì Conceptos Clave

### Gate vs Activation

- **Gate**: Peso decidido por el Reasoner (antes del forward)
- **Activation**: Salida del bloque (despu√©s del forward)
- **Relaci√≥n**: `activation_effective = activation_raw * gate`

### Top-K vs Threshold

- **Top-K**: Garantiza exactamente K bloques activos (sparse determinista)
- **Threshold**: N√∫mero variable seg√∫n confianza (sparse adaptativo)
- **Softmax**: Todos activos con pesos variables (denso)

### Evoluci√≥n vs Gradientes

- **Ventaja evoluci√≥n**: No requiere diferenciabilidad, explora bien
- **Ventaja gradientes**: M√°s eficiente en grandes dimensiones
- **Recomendaci√≥n**: Usa evoluci√≥n ahora, migra a PyTorch si necesitas escalar

---

**Implementaci√≥n completada**: Fase 31-B ‚úÖ  
**Autor**: Neural Core Project  
**Fecha**: Noviembre 2024  
**Versi√≥n**: 1.0
