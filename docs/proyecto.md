# ğŸ§  Neural Core - DocumentaciÃ³n del Proyecto

## ğŸ“‹ DescripciÃ³n General

**Neural Core** es un motor neuronal modular construido completamente en Python puro, diseÃ±ado para aprender y experimentar con redes neuronales desde cero, sin frameworks externos.

## ğŸ¯ Objetivos del Proyecto

- **Construir desde cero**: Implementar redes neuronales sin dependencias pesadas
- **Modularidad**: Cada componente es intercambiable y extensible
- **EducaciÃ³n**: CÃ³digo limpio y bien documentado para aprendizaje
- **ExperimentaciÃ³n**: Facilitar pruebas con diferentes arquitecturas y optimizadores

## ğŸ“ Estructura del Proyecto

```
neural_core/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py                 # Alias automÃ¡ticos (autograd/core/engine)
â”‚   â”œâ”€â”€ autograd/
â”‚   â”‚   â”œâ”€â”€ __init__.py             # Reexporta Value
â”‚   â”‚   â”œâ”€â”€ value.py                # Nodo autograd
â”‚   â”‚   â”œâ”€â”€ functional.py           # linear, mse_loss, etc.
â”‚   â”‚   â””â”€â”€ ops.py                  # Operaciones auxiliares
â”‚   â”œâ”€â”€ core/autograd_numpy/
â”‚   â”‚   â”œâ”€â”€ __init__.py             # Tensor + pÃ©rdidas vectorizadas (Fase 10)
â”‚   â”‚   â”œâ”€â”€ tensor.py               # Motor NumPy minimalista
â”‚   â”‚   â””â”€â”€ loss.py                 # MSE / BCE vectorizados
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py             # Componentes cognitivos
â”‚   â”‚   â”œâ”€â”€ memory_cell.py          # Celda de memoria diferenciable
â”‚   â”‚   â”œâ”€â”€ macro_neuron.py         # Macro-neurona con gating
â”‚   â”‚   â”œâ”€â”€ reasoning_unit.py       # Unidad de razonamiento
â”‚   â”‚   â”œâ”€â”€ cognitive_block.py      # Bloque cognitivo modular
â”‚   â”‚   â”œâ”€â”€ cognitive_graph.py      # Grafo de bloques cognitivos
â”‚   â”‚   â”œâ”€â”€ trm_block.py            # Tiny Recursive Model (Fase 10)
â”‚   â”‚   â”œâ”€â”€ trm_act_block.py        # TRM con ACT + deep supervision (Fase 11)
â”‚   â”‚   â”œâ”€â”€ cognitive_graph_trm.py  # Grafo TRM adaptativo (Fase 12)
â”‚   â”‚   â”œâ”€â”€ cognitive_graph_hybrid.py # Grafo hÃ­brido (Fase 13)
â”‚   â”‚   â”œâ”€â”€ projection_layer.py     # AutoAlign (Fase 14)
â”‚   â”‚   â”œâ”€â”€ training/               # Entrenamiento global (Fase 15)
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py         # Alias utilitarios de entrenamiento
â”‚   â”‚   â”‚   â”œâ”€â”€ losses.py           # MSE, L1, BCE vectorizados
â”‚   â”‚   â”‚   â”œâ”€â”€ optimizers.py       # SGD / Adam hÃ­bridos Value-Tensor
â”‚   â”‚   â”‚   â””â”€â”€ trainer.py          # GraphTrainer con deep supervision
â”‚   â”‚   â”œâ”€â”€ attention/              # AtenciÃ³n cognitiva dinÃ¡mica (Fase 16)
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py         # Exportaciones de atenciÃ³n
â”‚   â”‚   â”‚   â”œâ”€â”€ attention_layer.py  # Capa de atenciÃ³n Query-Key-Value
â”‚   â”‚   â”‚   â”œâ”€â”€ attention_router.py # Router de mÃºltiples atenciones
â”‚   â”‚   â”‚   â””â”€â”€ utils.py            # Softmax y utilidades numÃ©ricas
â”‚   â”‚   â””â”€â”€ monitor/                # Cognitive Monitor System (Fase 17)
â”‚   â”‚       â”œâ”€â”€ __init__.py         # Exportaciones de monitoreo
â”‚   â”‚       â”œâ”€â”€ cognitive_monitor.py# Seguimiento de activaciones/atenciÃ³n
â”‚   â”‚       â”œâ”€â”€ logger.py           # Logger JSON/timestamps
â”‚   â”‚       â””â”€â”€ visualizer_streamlit.py # Dashboard interactivo (Fase 19)
â”‚   â”œâ”€â”€ engine/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ trainer.py              # Entrenamiento supervisado
â”‚   â”‚   â”œâ”€â”€ rl_trainer.py           # Entrenamiento RL
â”‚   â”‚   â”œâ”€â”€ dataset.py              # Utilidades de datasets
â”‚   â”‚   â””â”€â”€ predictor.py            # Predictores utilitarios
â”‚   â””â”€â”€ app.py                      # Punto de entrada CLI
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ cognitive_agent_demo.py     # Bloque cognitivo secuencial
â”‚   â”œâ”€â”€ cognitive_graph_demo.py     # Grafo cognitivo (Fase 9)
â”‚   â”œâ”€â”€ trm_demo.py                 # XOR con TRM vectorizado (Fase 10)
â”‚   â”œâ”€â”€ trm_act_demo.py             # TRM con halting adaptativo (Fase 11)
â”‚   â”œâ”€â”€ trm_cognitive_graph_demo.py # Grafo TRM recursivo (Fase 12)
â”‚   â”œâ”€â”€ hybrid_graph_demo.py        # Grafo hÃ­brido TRM + CognitiveBlock (Fase 13)
â”‚   â”œâ”€â”€ hybrid_graph_autoalign_demo.py # AutoAlign dinÃ¡mico (Fase 14)
â”‚   â”œâ”€â”€ global_training_demo.py     # Entrenamiento global con deep supervision (Fase 15)
â”‚   â””â”€â”€ cognitive_attention_demo.py # AtenciÃ³n cognitiva dinÃ¡mica (Fase 16)
â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ app_dashboard.py            # App Streamlit del Cognitive Dashboard (Fase 19)
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_network.py
â”‚   â”œâ”€â”€ test_neuron.py
â”‚   â”œâ”€â”€ test_trainer.py
â”‚   â”œâ”€â”€ test_cognitive_graph_hybrid.py
â”‚   â”œâ”€â”€ test_graph_trainer.py
â”‚   â””â”€â”€ test_attention_router.py    # (Fase 16-17 - futuro)
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ proyecto.md                 # DocumentaciÃ³n general
â”œâ”€â”€ pyproject.toml                  # ConfiguraciÃ³n del proyecto
â””â”€â”€ README.md
```

## ğŸ§© Fases Completadas

### âœ… Fase 1 - Microneuronas y Activaciones
- **Neuronas individuales** con pesos, bias y funciones de activaciÃ³n
- **Funciones de activaciÃ³n**: sigmoid, relu, tanh, linear
- **Derivadas** para backpropagation

### âœ… Fase 2 - Capas y Red Neuronal
- **Capas de neuronas** con conectividad completa
- **Red multicapa** con propagaciÃ³n forward/backward
- **Estructura modular** [inputs, hidden, ..., outputs]

### âœ… Fase 3 - Backpropagation y Trainer
- **Backpropagation completa** desde cero
- **Trainer** para entrenamiento supervisado
- **ValidaciÃ³n de gradientes** y estabilidad

### âœ… Fase 4 - Optimizadores y Estabilidad
- **Optimizadores modulares**: SGD, Momentum, Adam, RMSprop
- **Tests de estabilidad** y validaciÃ³n de backprop
- **ComparaciÃ³n de optimizadores** en ejemplos

### âœ… Fase 5 - Variable Latente z y Proyector
- **Variable latente z** para planificaciÃ³n interna
- **LatentProjector** con proyecciÃ³n lineal + tanh
- **IntegraciÃ³n completa** en NeuralNetwork
- **Ejemplos de entrenamiento** con variable latente

### âœ… Fase 6 - Mini Framework Autograd
- **Motor autograd completo** con propagaciÃ³n automÃ¡tica
- **Nodo Value** con sobrecarga de operadores
- **Operaciones matemÃ¡ticas**: +, -, *, /, tanh, sigmoid, relu
- **API funcional**: linear, mse_loss
- **Entrenamiento XOR** usando autograd sin backprop manual
- **ComparaciÃ³n con backprop manual** validada

### âœ… Fase 7 - Macro-Neuronas Cognitivas
- **Celda de memoria diferenciable** con decaimiento temporal
- **Macro-neurona** que combina input + memoria + gating
- **Razonamiento secuencial** aprendido sin datasets
- **Sistema cognitivo** con contexto temporal
- **Demo de memoria** funcionando con autograd

### âœ… Fase 8 - CognitiveBlock (Arquitectura Cognitiva Modular)
- **ReasoningUnit**: Unidad que combina percepciÃ³n y memoria para inferencias
- **CognitiveBlock**: Bloque cognitivo completo con percepciÃ³n, memoria y razonamiento
- **Arquitectura modular**: Componentes interconectables para construir mentes artificiales
- **Demo de predicciÃ³n secuencial**: Aprende patrones temporales sin supervisiÃ³n
- **IntegraciÃ³n completa**: Todos los componentes usan el motor autograd

### âœ… Fase 9 - CognitiveGraph (Mente Modular Emergente)
- **CognitiveGraph**: Red de CognitiveBlock interconectados
- **ComunicaciÃ³n interbloques**: Feedforward, recurrente y reflexivo
- **Memoria compartida**: Estado global accesible por todos los bloques
- **Demo `cognitive_graph_demo.py`**: Mente artificial con percepciÃ³n â†’ razonamiento â†’ decisiÃ³n
- **Semilla determinista**: `random.seed(42)` para reproducibilidad
- **Alias automÃ¡ticos**: `src/__init__.py` expone `autograd`, `core` y `engine`

### âœ… Fase 10 - Motor Tensor Vectorizado + TRM Base
- **Tensor** NumPy (`core/autograd_numpy`) como reemplazo de `Value` para operaciones vectorizadas
- **Funciones de pÃ©rdida** MSE/BCE adaptadas al nuevo motor
- **TRMBlock** recursivo con estado latente z y detach entre pasos
- **Demo `examples/trm_demo.py`**: TRM aprende XOR con actualizaciÃ³n aproximada

### âœ… Fase 11 - Deep Supervision + Adaptive Computation Time
- **TRM_ACT_Block** con neurona de halting y cÃ¡lculo adaptativo de pasos
- **Deep supervision** en cada iteraciÃ³n con pÃ©rdidas parciales
- **Demo `examples/trm_act_demo.py`** validando razonamiento adaptativo en XOR

### âœ… Fase 12 - CognitiveGraph TRM
- **CognitiveGraphTRM** para orquestar mÃºltiples TRM_ACT conectados
- **Step numÃ©rico** y reset de estados para simulaciones recursivas
- **Demo `examples/trm_cognitive_graph_demo.py`**: pipeline percepciÃ³n â†’ razonamiento â†’ decisiÃ³n
- **Tests `tests/test_trm_cognitive_graph.py`** asegurando estabilidad y resets

### âœ… Fase 13 - CognitiveGraph Hybrid
- **CognitiveGraphHybrid** integra CognitiveBlock clÃ¡sicos y TRM_ACT adaptativos
- **Compatibilidad bidireccional**: convierte salidas entre Value â†” Tensor automÃ¡ticamente
- **Demo `examples/hybrid_graph_demo.py`** demostrando razonamiento mixto
- **Tests `tests/test_cognitive_graph_hybrid.py`** validando reset y estabilidad

### âœ… Fase 14 - AutoAlign Layers
- **ProjectionLayer** genera proyecciones lineales aprendibles entre bloques con dimensiones distintas
- **CognitiveGraphHybrid** ahora crea proyecciones on-the-fly al conectar nodos con tamaÃ±os incompatibles
- **Demo `examples/hybrid_graph_autoalign_demo.py`** muestra conexiones sensor â†’ memory â†’ reasoner â†’ decision con AutoAlign
- **Tests `tests/test_cognitive_graph_hybrid.py`** cubren estabilidad con AutoAlign activado

### âœ… Fase 15 - Deep Supervision Training Loop
- **GraphTrainer** entrena CognitiveGraphHybrid completo con supervisiÃ³n profunda
- **MÃ³dulos `core/training`** centralizan pÃ©rdidas, optimizadores y entrenamiento global
- **Compatibilidad hÃ­brida**: actualiza simultÃ¡neamente CognitiveBlock, TRM_ACT_Block y ProjectionLayer
- **Demo `examples/global_training_demo.py`** aprende XOR extremo a extremo
- **Tests `tests/test_graph_trainer.py`** validan recolecciÃ³n de parÃ¡metros y paso de entrenamiento

### âœ… Fase 16 - Cognitive Attention System (CAS)
- **CognitiveAttentionLayer** calcula atenciÃ³n contextual Query-Key-Value entre bloques
- **AttentionRouter** coordina pesos dinÃ¡micos para cada conexiÃ³n del grafo
- **CognitiveGraphHybrid** integra atenciÃ³n + AutoAlign para foco cognitivo adaptativo
- **Demo `examples/cognitive_attention_demo.py`** muestra cÃ³mo varÃ­a el foco en tiempo real
- **Tests `tests/test_cognitive_graph_hybrid.py`** verifican almacenamiento y normalizaciÃ³n de pesos de atenciÃ³n

### âœ… Fase 17 - Cognitive Monitor System (CMS)
- **CognitiveMonitor** registra activaciones, pesos de atenciÃ³n y pÃ©rdidas en tiempo real
- **CognitiveLogger** provee logging estructurado en consola/JSON con timestamps
- **IntegraciÃ³n** desde CognitiveGraphHybrid y GraphTrainer para telemetrÃ­a continua
- **Demo `examples/cognitive_monitor_demo.py`** ejecuta entrenamiento XOR monitorizado
- **Datos persistentes** listos para dashboards (Streamlit en Fase 19)

### âœ… Fase 18 - Memory Replay System (MRS)
- **EpisodicMemory** almacena inputs, targets, outputs, pÃ©rdidas y mapas de atenciÃ³n
- **MemoryReplaySystem** consolida experiencias exitosas mediante sleep cycles
- **GraphTrainer** registra cada episodio automÃ¡ticamente durante el entrenamiento
- **Fase de sueÃ±o** con `sleep_and_replay()` que reduce la pÃ©rdida promedio
- **Demo `examples/memory_replay_demo.py`** muestra consolidaciÃ³n tras 300 Ã©pocas

### âœ… Fase 19 - Cognitive Dashboard (Streamlit)
- **CognitiveVisualizer** renderiza pÃ©rdidas, activaciones, atenciÃ³n y memoria en tiempo real
- **App Streamlit** `dashboard/app_dashboard.py` consume el grafo activo vÃ­a `st.session_state`
- **IntegraciÃ³n opcional**: demos pueden lanzar el dashboard en segundo plano
- **Dependencias aÃ±adidas**: `streamlit`, `pandas`, `plotly`, `altair`, `pydeck`
- **Interfaz** multipestaÃ±a con mÃ©tricas clave actualizadas durante entrenamiento y sleep cycles

### âœ… Fase 20 - Meta-Learning Loop
- **Paquete `core.meta`** con reglas adaptativas (`adaptive_lr`, `adaptive_focus`, `adaptive_sleep`) que observan pÃ©rdidas y atenciones del monitor
- **MetaLearningController** ajusta dinÃ¡micamente learning rate, foco atencional e intervalo de consolidaciÃ³n usando el monitor y el MemoryReplaySystem
- **Demo `examples/meta_learning_demo.py`** (`PYTHONPATH=src uv run python examples/meta_learning_demo.py`) muestra el bucle autorregulado en acciÃ³n
- **Tests `tests/test_meta_rules.py`** validan las heurÃ­sticas de ajuste
- Detalles ampliados en `docs/fase20_meta_loop.md`

### âœ… Fase 21 - Cognitive Evolution System (CES)
- **Paquete `core.evolution`** con `CognitivePopulation`, utilidades de crossover y el `EvolutionManager` para coordinar generaciones
- **Crossover hÃ­brido** que mezcla pesos tipo Value/Tensor con mutaciones ligeras para mantener diversidad
- **EvoluciÃ³n generacional**: selecciÃ³n de los grafos con mejor fitness, cruce y regeneraciÃ³n automÃ¡tica de la poblaciÃ³n
- **Demo `examples/cognitive_evolution_demo.py`** (`PYTHONPATH=src uv run python examples/cognitive_evolution_demo.py`) ejecuta varias generaciones sobre XOR
- Permite experimentar con evoluciÃ³n de arquitecturas sin alterar el flujo de entrenamiento base

### âœ… Fase 22 - Cognitive Society System (CSS)
- **Paquete `core.society`** con `CognitiveAgent`, `CommunicationChannel` y `SocietyManager` para coordinar agentes mÃºltiples
- **Intercambio social**: agentes comparten experiencias vÃ­a `exchange_memories` y broadcasts de mejores episodios
- **CooperaciÃ³n adaptativa**: cada agente entrena su propio grafo pero se beneficia de memorias ajenas
- **Demo `examples/cognitive_society_demo.py`** (`PYTHONPATH=src uv run python examples/cognitive_society_demo.py`) muestra cÃ³mo convergen las pÃ©rdidas compartiendo conocimiento

### âœ… Fase 23A - Cognitive API Server (CAS)
- **Paquete `api/`** con servidor FastAPI, routers modulares y estado compartido (`CognitiveAppState`)
- **Endpoints REST**: `/predict`, `/feedback`, `/evolve`, `/status` para interactuar con la sociedad en tiempo real
- **IntegraciÃ³n con `.env`**: API key y parÃ¡metros de despliegue para una configuraciÃ³n segura en la Orange Pi
- **Script de arranque** (via `uvicorn src.api.server:app --host 0.0.0.0 --port 8000`), listo para exponerse tras un reverse proxy HTTPS
- **Monitoreo en vivo**: `/status` reporta pÃ©rdidas recientes, memoria y espectro de agentes activos

### âœ… Fase 23B - Cognitive Persistence Layer (CPL)
- **Paquete `core.persistence`** con gestores de rutas, serializaciÃ³n de pesos/memorias y `PersistenceManager`
- **Formato ligero**: pesos en `.npz` comprimido, memorias y mÃ©tricas en `.json` human-readable
- **IntegraciÃ³n con API**: carga automÃ¡tica al iniciar servidor y endpoint `/save` para persistencia manual o vÃ­a cron
- **Directorios `data/persistence/weights|memories`** almacenan hasta 100 episodios recientes por agente
- Asegura continuidad del aprendizaje tras reinicios o despliegues en nodos distribuidos

### âœ… Fase 23C - Cognitive Network (DistribuciÃ³n de Agentes)
- **Paquete `core.distribution`** con `CognitiveDistributor` (cliente HTTP) y helpers de recepciÃ³n
- **Endpoint `/share`** en FastAPI para sincronizar memorias/pesos entre nodos protegidos por API key
- **SerializaciÃ³n remota**: transferencias usan `.npz` base64 y memorias recientes en JSON (lÃ­mite configurable)
- **Tests `tests/test_distribution.py`** validan generaciÃ³n de payload y aplicaciÃ³n remota en entornos aislados
- Permite interconectar Orangeâ€¯Pi, servidores cloud o PCs formando una red de sociedades cognitivas cooperativas

### âœ… Fase 24 - Cognitive Federation (Aprendizaje Federado)
- **Paquete `core.federation`** con utilidades de serializaciÃ³n/promedio y `FederatedClient`
- **Router `/federate`** en FastAPI (servidor cloud) agrega pesos (`/upload`) y entrega promedio global (`/global`)
- **Seguridad**: dependencia `require_api_key` y helper `get_api_headers` reutilizados por distribuidores y clientes
- **Tests `tests/test_federation.py`** cubren serializaciÃ³n, promedio y roundtrip cliente-servidor (requiere FastAPI instalado)
- Permite que nodos locales entrenen con sus datos y sincronicen pesos con un nodo federador sin exponer datos crudos

### âœ… Fase 25 - Cognitive Scheduler (Ciclo AutÃ³nomo)
- **Paquete `core.scheduler`** con `SchedulerConfig` (intervalos/flags) y `CognitiveScheduler` en hilo daemon
- **Ciclos automatizados**: entrenamiento, persistencia, federaciÃ³n opcional, intercambio de memorias y sueÃ±o cognitivo
- **Integrado en `api/dependencies.py`**: se instancia en el arranque, reutilizando `PersistenceManager` y `FederatedClient`
- **ConfiguraciÃ³n flexible** (`loop_sleep`, banderas `enable_*`) permite desactivar federaciÃ³n/evoluciÃ³n en nodos aislados
- DiseÃ±ado para mantener la sociedad aprendiendo sin intervenciÃ³n manual, alineado con despliegues Orangeâ€¯Pi + nube

### âœ… Fase 26 - Latent Planner (PlanificaciÃ³n Latente)
- **Bloque `core.latent_planner_block.LatentPlannerBlock`** extiende `TRM_ACT_Block` con una etapa `plan()` que produce `z_plan`
- **Opciones configurables**: `detach_each_step` para supervisiÃ³n profunda y `retain_plan` para exponer el plan a memoria/monitoring
- **Demo `examples/latent_planner_demo.py`** muestra inferencia y mÃ©tricas del plan; **test `tests/test_latent_planner.py`** asegura estabilidad
- **IntegraciÃ³n sugerida**: usar `get_last_plan()` en dashboards, almacenar `z_plan` en replay y condicionarlo en mÃ³dulos de atenciÃ³n/federaciÃ³n

### âœ… Fase 27 - PyG Bridge (IntegraciÃ³n con PyTorch Geometric)
- **Paquete `core.pyg_bridge`** con adaptador (`CognitiveGraphAdapter`), modelos GNN (`GCNReasoner`, `GATReasoner`) y `GraphTrainer`
- **Adapter** convierte `CognitiveGraphHybrid` en `torch_geometric.data.Data` incluyendo activaciones y promedios de planes latentes
- **Demo `examples/pyg_bridge_demo.py`** entrena un GCN sobre el grafo hÃ­brido; **test `tests/test_pyg_bridge.py`** valida adaptaciÃ³n y trainer (con PyG instalado)
- **Requisitos opcionales**: instalar `torch` y `torch_geometric` para habilitar visualizaciÃ³n, razonamiento estructural y futuros dashboards (Fase 28)

### âœ… Fase 28 - PyG Visualization Dashboard
- **`dashboard/dashboard_pyg_viz.py`** crea una vista Streamlit que toma el grafo (vÃ­a `CognitiveGraphAdapter`) y lo visualiza con NetworkX + Matplotlib
- **Colores por `z_plan`** y tabla con activaciÃ³n media, intensidad latente y salida del razonador `GCNReasoner`
- **Listo para integraciÃ³n remota**: reemplazar el loader demo por un consumidor de `/api/graph/state` en Orangeâ€¯Pi/Cloud para visualizar nodos reales
- **Dependencias aÃ±adidas**: `torch`, `torch-geometric` y `matplotlib` en `pyproject.toml`; `uv lock` actualizado

### âœ… Fase 29 - Cognitive Graph Interactive Visualizer
- **`dashboard/dashboard_pyg_interactive.py`** agrega un visualizador interactivo con Plotly para mover nodos y hacer zoom
- **Razonador `GATReasoner`** calcula salidas por nodo; panel lateral muestra mÃ©tricas (`z_plan`, salida GAT) y tabla resumen
- **Interactividad**: hover con nombres, selecciÃ³n por `selectbox`, colores por intensidad latente, preparado para consumir WebSockets/REST en tiempo real
- **Requisitos**: dependen de Fase 27/28 (PyTorch + PyG) mÃ¡s Plotly (ya presente) y NetworkX (incluido con PyG)

### âœ… Fase 30 - Live Cognitive Stream
- **Backend**: WebSocket `/ws/graph_state` (FastAPI) publica el grafo cognitivo serializado cada 2 s usando `CognitiveGraphAdapter`
- **Frontend**: `dashboard/dashboard_live_stream.py` escucha con `websocket-client`, actualiza un grÃ¡fico Plotly y tabla Streamlit en tiempo real
- **IntegraciÃ³n**: reusa `get_app_state()` para acceder al grafo activo; listo para conectar nodos Orange Pi/Cloud mediante tÃºnel seguro
- **Dependencias**: agrega `websocket-client` a `pyproject.toml`; `uv lock` actualizado

### âœ… Fase 31-B - Cognitive Reasoning Layer
- **Paquete `core.reasoning`** con `Reasoner` (MLP ligero en NumPy) que decide gates de activaciÃ³n por bloque
- **MÃ©todo `forward_with_reasoner`** en `CognitiveGraphHybrid` ejecuta el grafo selectivamente segÃºn decisiones del Reasoner
- **Modos de gating**: softmax (distribuciÃ³n continua), top-k (sparse), threshold (umbral adaptativo)
- **Entrenamiento evolutivo**: `evolve_reasoner_on_task()` optimiza el Reasoner sin gradientes mediante mutaciÃ³n y selecciÃ³n
- **Utilidades**: `evaluate_reasoner()`, `extract_gates_history()` para anÃ¡lisis y visualizaciÃ³n de decisiones
- **Demos**: `examples/cognitive_reasoning_demo.py` (inferencia bÃ¡sica) y `examples/cognitive_reasoning_evolution_demo.py` (entrenamiento en XOR)
- **IntegraciÃ³n**: compatible con LatentPlannerBlock, TRM_ACT_Block y atenciÃ³n cognitiva; gates guardados en `graph.last_gates` para dashboards
- **Persistencia**: `reasoner.state_dict()` y `load_state_dict()` para guardar/cargar pesos optimizados

### âœ… Fase 32 - Reasoner Integration & Dashboard
- **ReasonerManager** centraliza gestiÃ³n del Reasoner con thread-safety, evoluciÃ³n async y persistencia .npz
- **API REST completa** (`/reasoner/*`): status, gates, predict, evolve, save, load, reset con FastAPI
- **IntegraciÃ³n con CognitiveAppState**: ReasonerManager inicializado automÃ¡ticamente al arrancar servidor
- **PersistenceManager extendido**: guarda/carga Reasoner junto con pesos del grafo automÃ¡ticamente
- **Dashboard de control** (`dashboard_reasoner_panel.py`): panel Streamlit para monitoreo y control del Reasoner
- **Dashboard PyG con Reasoner** (`dashboard_pyg_with_reasoner.py`): visualizaciÃ³n integrada de grafo + gates en tiempo real
- **EvoluciÃ³n con evaluaciÃ³n real**: endpoint `/evolve` usa el grafo activo para fitness (no placeholders)
- **Auto-persistencia**: Reasoner se guarda/carga automÃ¡ticamente en `data/persistence/reasoner_state.npz`

### âœ… Fase 33 - Curriculum Learning System
- **Sistema de aprendizaje progresivo**: el Reasoner aprende de tareas simples a complejas (identity â†’ xor â†’ parity â†’ reasoning)
- **7 tareas pre-configuradas**: identity, xor, parity, counting, sequence, memory, reasoning con dificultad creciente
- **MÃ©tricas cognitivas avanzadas**: MSE, MAE, accuracy, gate diversity, gate entropy, convergence rate, stability (8 mÃ©tricas)
- **CurriculumManager profesional**: sin variables globales, inyecciÃ³n de dependencias, thread-safe con RLock
- **Checkpointing automÃ¡tico**: guarda estado despuÃ©s de cada etapa, resume desde Ãºltima completada
- **API REST completa** (`/curriculum/*`): start, status, pause, resume, reset, history, checkpoints, export
- **Dashboard Curriculum** (`dashboard_curriculum.py`): visualizaciÃ³n en tiempo real de progreso, historial y mÃ©tricas
- **Early stopping inteligente**: success_threshold y fail_threshold por etapa, evoluciÃ³n ligera adaptativa
- **Tests exhaustivos**: 20+ tests unitarios y de integraciÃ³n en `tests/test_curriculum.py`
- **DocumentaciÃ³n completa**: `docs/fase33_curriculum_learning.md` con ejemplos, API, guÃ­as y troubleshooting

#### â–¶ï¸ CÃ³mo lanzar los dashboards

> **âš ï¸ Nota importante**: Todos los comandos deben ejecutarse desde la raÃ­z del proyecto: `/home/gonzapython/Documentos/Redes_Neuronales/neural_core`

---

### ğŸ¯ **Setup Completo (Recomendado para Fase 32)**

Para visualizar el Reasoner en acciÃ³n, ejecuta estos 3 comandos en terminales separadas:

```bash
# Terminal 1: Servidor FastAPI con Reasoner integrado
PYTHONPATH=src uv run uvicorn api.server:app --reload
# Accede: http://localhost:8000 (API REST)

# Terminal 2: Panel de control del Reasoner
PYTHONPATH=src uv run streamlit run dashboard/dashboard_reasoner_panel.py
# Accede: http://localhost:8501 (Control de evoluciÃ³n, mÃ©tricas, save/load)

# Terminal 3: VisualizaciÃ³n del grafo con gates
PYTHONPATH=src uv run streamlit run dashboard/dashboard_pyg_with_reasoner.py
# Accede: http://localhost:8502 (Grafo interactivo con gates en tiempo real)
```

**CaracterÃ­sticas del setup completo**:
- ğŸ® Control total del Reasoner (evoluciÃ³n, persistencia)
- ğŸ“Š MÃ©tricas en tiempo real (loss, generaciÃ³n, gates)
- ğŸ¨ VisualizaciÃ³n de grafo cognitivo con nodos coloreados por gates
- ğŸ”„ Auto-refresh configurable (1-10 segundos)

---

### ğŸ“‹ **Dashboards Disponibles por Fase**

#### 1ï¸âƒ£ **Dashboard Principal - Monitor Cognitivo** (Fases 19-21)

**OpciÃ³n A: Script integrado**
```bash
PYTHONPATH=src uv run python launch_cognitive.py
```
- Entrena automÃ¡ticamente y levanta dashboard en http://localhost:8501
- Persiste snapshots en `dashboard_state.json`

**OpciÃ³n B: Procesos separados**
```bash
# Terminal 1: Entrenamiento
PYTHONPATH=src uv run python examples/memory_replay_demo.py

# Terminal 2: Dashboard
PYTHONPATH=src uv run streamlit run dashboard/app_dashboard.py
```

**CaracterÃ­sticas**:
- ğŸ“‰ PÃ©rdidas de entrenamiento
- ğŸ§  Activaciones por bloque
- ğŸ‘ï¸ AtenciÃ³n cognitiva
- ğŸ’¾ Memoria episÃ³dica

---

#### 2ï¸âƒ£ **Dashboard PyG Visualization** (Fase 28)

```bash
PYTHONPATH=src uv run streamlit run dashboard/dashboard_pyg_viz.py
```
**Accede**: http://localhost:8501

**CaracterÃ­sticas**:
- ğŸ¨ Grafo hÃ­brido coloreado por intensidad `z_plan`
- ğŸ“Š Tabla con activaciÃ³n media, plan latente, salida GCNReasoner
- ğŸ”— Preparado para conectar con nodos remotos via API

---

#### 3ï¸âƒ£ **Dashboard PyG Interactive** (Fase 29)

```bash
PYTHONPATH=src uv run streamlit run dashboard/dashboard_pyg_interactive.py
```
**Accede**: http://localhost:8501

**CaracterÃ­sticas**:
- ğŸ–±ï¸ Nodos movibles (drag & drop)
- ğŸ” Zoom interactivo
- ğŸ“Š MÃ©tricas al seleccionar bloques
- ğŸ§  GATReasoner para representar salidas

---

#### 4ï¸âƒ£ **Live Cognitive Stream** (Fase 30)

```bash
# Terminal 1: Backend WebSocket
PYTHONPATH=src uv run uvicorn api.server:app --reload

# Terminal 2: Dashboard streaming
PYTHONPATH=src uv run streamlit run dashboard/dashboard_live_stream.py
```
**Accede**: 
- Backend: http://localhost:8000
- Dashboard: http://localhost:8501

**CaracterÃ­sticas**:
- ğŸ”„ ConexiÃ³n WebSocket a `ws://localhost:8000/ws/graph_state`
- â±ï¸ Actualizaciones cada 2 segundos
- ğŸŒ Configurable para nodos remotos o tÃºnel Cloudflare

---

#### 5ï¸âƒ£ **Reasoner Control Panel** (Fase 32) â­ NUEVO

```bash
# Requiere servidor corriendo (ver Terminal 1 del setup completo)
PYTHONPATH=src uv run streamlit run dashboard/dashboard_reasoner_panel.py
```
**Accede**: http://localhost:8501

**CaracterÃ­sticas**:
- ğŸ® **Control de evoluciÃ³n**: Iniciar/detener con parÃ¡metros configurables
- ğŸ“Š **MÃ©tricas en tiempo real**: Best loss, generaciÃ³n, progreso
- ğŸ“ˆ **GrÃ¡fico de barras**: Gates actuales por bloque
- ğŸ“‹ **Historial**: Ãšltimos 5 steps de gates aplicados
- ğŸ’¾ **Persistencia**: Save/Load con un click
- âš™ï¸ **Auto-refresh**: ActualizaciÃ³n cada 1-10 segundos

**Controles disponibles**:
- Slider de generaciones (10-200)
- Slider de poblaciÃ³n (4-20)
- Slider de mutaciÃ³n (0.01-0.1)
- Botones: Evolve, Stop, Save, Load

---

#### 6ï¸âƒ£ **Dashboard PyG + Reasoner** (Fase 32) â­

```bash
# Requiere servidor corriendo
PYTHONPATH=src uv run streamlit run dashboard/dashboard_pyg_with_reasoner.py
```
**Accede**: http://localhost:8502

**CaracterÃ­sticas**:
- ğŸ¨ **Grafo interactivo Plotly**: Nodos movibles, zoom, hover con detalles
- ğŸŒˆ **Coloreo dual**: Por plan latente O por gates del Reasoner
- ğŸ“Š **MÃ©tricas por bloque**: ActivaciÃ³n, plan, GAT output, gate
- ğŸ“‹ **Tabla detallada**: Todas las features en formato tabular
- ğŸ”„ **Auto-refresh**: Sincronizado con evoluciÃ³n del Reasoner
- ğŸ‘ï¸ **Estado del Reasoner**: Visible en sidebar (running/listo, best loss)

**Interactividad**:
- Selector: "Colorear nodos por" â†’ plan / gates
- Checkbox: Auto-refresh activado/desactivado
- Slider: Intervalo de actualizaciÃ³n (1-10s)

---

#### 7ï¸âƒ£ **Dashboard Curriculum Learning** (Fase 33) â­ NUEVO

```bash
# Requiere servidor corriendo
PYTHONPATH=src uv run streamlit run dashboard/dashboard_curriculum.py
```
**Accede**: http://localhost:8503

**CaracterÃ­sticas**:
- ğŸ“Š **Estado general**: Progress bar, etapa actual, completadas
- ğŸ“ˆ **EvoluciÃ³n del loss**: GrÃ¡fico interactivo por etapa
- ğŸ“Š **Epochs por etapa**: Bar chart con coloreo por dificultad
- ğŸ“‹ **Tabla detallada**: Status, loss, accuracy, gate diversity por etapa
- ğŸ“‰ **EstadÃ­sticas globales**: Total epochs, avg loss, avg accuracy, completion rate
- ğŸ“š **Lista de etapas**: VisualizaciÃ³n de todas las etapas (completadas/actuales/pendientes)
- ğŸ® **Controles**: Start, Pause, Reset del curriculum
- âš™ï¸ **Auto-refresh**: ActualizaciÃ³n automÃ¡tica cada 1-10 segundos
- ğŸ“‹ **Presets**: EstÃ¡ndar (7 etapas), RÃ¡pido (4 etapas), Avanzado (10 etapas), Personalizado

**Flujo de trabajo**:
1. Servidor corriendo en terminal 1
2. Dashboard abierto en terminal 2
3. Click en "â–¶ï¸ Start" para iniciar curriculum
4. Observar progreso en tiempo real
5. El Reasoner aprende progresivamente de simple a complejo

---

### ğŸš€ **Flujo de Trabajo Recomendado**

#### Para Fase 33 (Curriculum Learning): â­ RECOMENDADO

1. **Arrancar servidor** (Terminal 1):
   ```bash
   PYTHONPATH=src uv run uvicorn api.server:app --reload
   ```
   Espera ver: `[ReasonerManager] Inicializado...`

2. **Abrir dashboard curriculum** (Terminal 2):
   ```bash
   PYTHONPATH=src uv run streamlit run dashboard/dashboard_curriculum.py
   ```
   - Click en **â–¶ï¸ Start** para iniciar curriculum estÃ¡ndar (7 etapas)
   - Observa progreso en tiempo real con grÃ¡ficos y mÃ©tricas
   - El Reasoner aprende progresivamente: identity â†’ xor â†’ parity â†’ ...

3. **Opcional: Dashboard PyG** (Terminal 3):
   ```bash
   PYTHONPATH=src uv run streamlit run dashboard/dashboard_pyg_with_reasoner.py
   ```
   - Ver cÃ³mo el grafo cambia mientras aprende
   - Observar gates actualizÃ¡ndose en tiempo real

4. **Al finalizar**:
   - El Reasoner entrenado se guarda automÃ¡ticamente
   - Checkpoint disponible en `data/curriculum/curriculum_state.json`
   - Historial accesible via API: `curl http://localhost:8000/curriculum/history | jq`

---

#### Para Fase 32 (Reasoner + VisualizaciÃ³n):

1. **Arrancar servidor** (Terminal 1):
   ```bash
   PYTHONPATH=src uv run uvicorn api.server:app --reload
   ```
   Espera ver: `[ReasonerManager] Inicializado: X bloques...`

2. **Abrir panel de control** (Terminal 2):
   ```bash
   PYTHONPATH=src uv run streamlit run dashboard/dashboard_reasoner_panel.py
   ```
   - Ajusta parÃ¡metros con sliders
   - Click en **â–¶ï¸ Evolve**
   - Observa mÃ©tricas actualizÃ¡ndose

3. **Abrir visualizaciÃ³n PyG** (Terminal 3):
   ```bash
   PYTHONPATH=src uv run streamlit run dashboard/dashboard_pyg_with_reasoner.py
   ```
   - Selecciona "gates" en el selector
   - Observa nodos cambiar de color mientras evoluciona
   - Ve la tabla con todas las features

4. **Guardar progreso**:
   - En el panel de control, click **ğŸ’¾ Save**
   - El Reasoner se guarda en `data/persistence/reasoner_state.npz`

---

### ğŸ“¡ **API REST Endpoints** (Fase 32)

Con el servidor corriendo, puedes usar estos endpoints:

```bash
# Estado del Reasoner
curl http://localhost:8000/reasoner/status | jq

# Gates recientes
curl http://localhost:8000/reasoner/gates?n=10 | jq

# Iniciar evoluciÃ³n (50 generaciones)
curl -X POST http://localhost:8000/reasoner/evolve \
  -H "Content-Type: application/json" \
  -d '{"generations": 50, "pop_size": 10, "mutation_scale": 0.03}'

# Detener evoluciÃ³n
curl -X POST http://localhost:8000/reasoner/evolve/stop

# Guardar estado
curl -X POST http://localhost:8000/reasoner/save

# Cargar estado
curl -X POST http://localhost:8000/reasoner/load
```

---

### ğŸ› **Troubleshooting**

**Error: "Address already in use"**
```bash
# Matar proceso en puerto 8000
kill -9 $(lsof -ti:8000)
```

**Error: "ModuleNotFoundError: torch"**
```bash
uv pip install torch torch-geometric
```

**Dashboard no conecta a API**
- Verifica que el servidor estÃ© corriendo: `curl http://localhost:8000/reasoner/status`
- Reinicia el servidor si es necesario

**Streamlit muestra error de "Duplicate Element"**
- Presiona **R** para recargar el dashboard
- O reinicia con Ctrl+C y vuelve a ejecutar el comando




## ğŸ§  Estructura Completa del Proyecto

### ğŸ”§ Componentes Implementados:

#### **Value - Nodo Base**
```python
from autograd.value import Value

# Crear valores con autograd
x = Value(2.0)
y = Value(3.0)
z = x * y + x.relu()  # Operaciones encadenadas
z.backward()  # PropagaciÃ³n automÃ¡tica
print(x.grad)  # Gradiente calculado automÃ¡ticamente
```

#### **Operaciones Disponibles**
- **AritmÃ©ticas**: +, -, *, /, **
- **Activaciones**: tanh, sigmoid, relu, leaky_relu
- **Funciones**: exp, log
- **Red**: linear, mse_loss

#### **Ejemplo de Uso**
```python
# Entrenamiento XOR con autograd
from autograd.value import Value
from autograd.functional import linear, mse_loss

# Crear red con autograd
layer1 = make_layer(2, 4)  # Pesos como Value
layer2 = make_layer(4, 1)

# Forward automÃ¡tico
y_pred = forward(x)
loss = mse_loss(y_pred, y)
loss.backward()  # Â¡Sin backprop manual!
```

### ğŸ¯ Resultados Fase 6:
- **âœ… Motor autograd funcional** sin dependencias
- **âœ… PropagaciÃ³n automÃ¡tica** de gradientes
- **âœ… API intuitiva** estilo PyTorch
- **âœ… Entrenamiento XOR** convergente
- **âœ… ValidaciÃ³n** contra backprop manual

### ğŸ“Š ComparaciÃ³n de Enfoques:
| Enfoque | Backprop | Complejidad | Flexibilidad |
|---------|----------|-------------|--------------|
| Manual  | Manual   | Alta        | Baja         |
| Autograd| AutomÃ¡tica| Baja        | Alta         |

### ğŸš€ PrÃ³ximos Pasos:
- **Fase 10**: Sistemas cognitivos multi-agente
- **VectorizaciÃ³n**: OptimizaciÃ³n con NumPy (opcional)
- **Persistencia**: Guardado/carga de pesos
- **Exportar mÃ¡s alias**: Evaluar exposiciÃ³n plana de `io`, `examples`

## ğŸš€ Uso RÃ¡pido

### Ejemplo BÃ¡sico - XOR
```python
from core.network import NeuralNetwork
from core import losses
from core.optimizers import Adam
from engine.trainer import Trainer

# Dataset XOR
dataset = [
    ([0.0, 0.0], [0.0]),
    ([0.0, 1.0], [1.0]),
    ([1.0, 0.0], [1.0]),
    ([1.0, 1.0], [0.0]),
]

# Crear red
nn = NeuralNetwork([2, 4, 1], activation="sigmoid")

# Entrenar
trainer = Trainer(
    nn,
    loss_fn=losses.mse_loss,
    loss_grad_fn=losses.mse_grad,
    optimizer=Adam(lr=0.01),
    batch_size=1
)

trainer.train(dataset, epochs=2000, verbose=True)
```

### ComparaciÃ³n de Optimizadores
```python
from core.optimizers import SGD, SGDMomentum, Adam, RMSprop

# Probar diferentes optimizadores
optimizers = [
    ("SGD", SGD(lr=0.1)),
    ("Momentum", SGDMomentum(lr=0.05, momentum=0.9)),
    ("Adam", Adam(lr=0.01)),
    ("RMSprop", RMSprop(lr=0.01)),
]

for name, optimizer in optimizers:
    trainer = Trainer(nn, losses.mse_loss, losses.mse_grad, optimizer=optimizer)
    trainer.train(dataset, epochs=1000)
```

## ğŸ§ª EjecuciÃ³n de Tests

### Tests de ValidaciÃ³n
```bash
# Instalar dependencias
uv sync

# Ejecutar todos los tests
uv run python run_tests.py

# Tests individuales
uv run python -m pytest tests/test_stability.py -v
```

### Ejemplos
```bash
# XOR con Adam
uv run python examples/train_xor.py

# Comparar optimizadores
uv run python examples/compare_optimizers.py
```

## ğŸ“Š Arquitectura del Sistema

### Microneurona (Neuron)
```python
class Neuron:
    def __init__(self, n_inputs: int, activation: str = "sigmoid", optimizer: Optimizer = None):
        self.weights: List[float]  # Pesos sinÃ¡pticos
        self.bias: float           # Sesgo
        self.activation: Activation # FunciÃ³n de activaciÃ³n
        self.optimizer: Optimizer   # Optimizador configurable
    
    def forward(self, inputs: List[float]) -> float:
        # PropagaciÃ³n hacia adelante
        pass
    
    def apply_gradients(self, dweights: List[float], dbias: float) -> None:
        # ActualizaciÃ³n con optimizador
        pass
```

### Red Neuronal (NeuralNetwork)
```python
class NeuralNetwork:
    def __init__(self, layer_sizes: List[int], activation: str = "sigmoid"):
        # [n_inputs, n_hidden1, n_hidden2, ..., n_outputs]
        pass
    
    def forward(self, inputs: List[float], z: List[float] = None) -> List[float]:
        # Forward con soporte para variables latentes
        pass
    
    def train_step(self, inputs: List[float], targets: List[float], lr: float) -> float:
        # Un paso completo de entrenamiento
        pass
```

## ğŸ¯ CaracterÃ­sticas Implementadas

### âœ… Funcionalidad Base
- **Redes feedforward** multicapa
- **Backpropagation** completo
- **Funciones de activaciÃ³n** con derivadas
- **Funciones de pÃ©rdida** MSE y BCE
- **OptimizaciÃ³n** con mÃºltiples algoritmos

### âœ… ValidaciÃ³n
- **Tests de estabilidad** con XOR
- **VerificaciÃ³n de convergencia**
- **ValidaciÃ³n numÃ©rica**
- **Sin dependencias externas pesadas**

### âœ… Modularidad
- **Componentes intercambiables**
- **Optimizadores plug-and-play**
- **Funciones de activaciÃ³n extensibles**
- **Tests automatizados**

## ğŸš€ PrÃ³ximos Pasos - Fase 20

### ğŸ§  Memory Replay Dashboard Avanzado
- **Controles interactivos** para filtrar episodios y ajustar replay_factor
- **Comparativa de sesiones** con descargas CSV desde Streamlit

### ğŸ“ˆ Escalabilidad
- **Batch processing** con NumPy para TRM y grafo cognitivo
- **EstadÃ­sticas de halting** y visualizaciÃ³n de pasos de razonamiento
- **Persistencia** de modelos y replay de grafos cognitivos

## ğŸ“‹ Requisitos

- **Python**: >= 3.12
- **Gestor de paquetes**: uv (recomendado)
- **Sistema operativo**: Linux/macOS/Windows

## ğŸ† Logros

- âœ… **0 dependencias pesadas** - Python puro
- âœ… **100% modular** - Cada componente es intercambiable
- âœ… **Tests completos** - ValidaciÃ³n exhaustiva
- âœ… **DocumentaciÃ³n clara** - CÃ³digo educativo
- âœ… **Ejemplos prÃ¡cticos** - XOR y comparaciones

## ğŸ“ PropÃ³sito Educativo

Este proyecto sirve como:
- **Plataforma de aprendizaje** para redes neuronales
- **Base para experimentaciÃ³n** con arquitecturas
- **DemostraciÃ³n** de backpropagation desde cero
- **Puente** hacia frameworks mÃ¡s complejos

---


