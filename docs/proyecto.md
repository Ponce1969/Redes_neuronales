# ğŸ§  Neural Core - DocumentaciÃ³n del Proyecto

## ğŸ“‹ DescripciÃ³n General

**Neural Core** es un motor neuronal modular construido completamente en Python puro, diseÃ±ado para aprender y experimentar con redes neuronales desde cero, sin frameworks externos.

## ğŸ¯ Objetivos del Proyecto

- **Construir desde cero**: Implementar redes neuronales sin dependencias pesadas
- **Modularidad**: Cada componente es intercambiable y extensible
- **EducaciÃ³n**: CÃ³digo limpio y bien documentado para aprendizaje
- **ExperimentaciÃ³n**: Facilitar pruebas con diferentes arquitecturas y optimizadores

## ğŸ“ Estructura del Proyecto

```
neural_core/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py                 # Alias automÃ¡ticos (autograd/core/engine)
â”‚   â”œâ”€â”€ autograd/
â”‚   â”‚   â”œâ”€â”€ __init__.py             # Reexporta Value
â”‚   â”‚   â”œâ”€â”€ value.py                # Nodo autograd
â”‚   â”‚   â”œâ”€â”€ functional.py           # linear, mse_loss, etc.
â”‚   â”‚   â””â”€â”€ ops.py                  # Operaciones auxiliares
â”‚   â”œâ”€â”€ core/autograd_numpy/
â”‚   â”‚   â”œâ”€â”€ __init__.py             # Tensor + pÃ©rdidas vectorizadas (Fase 10)
â”‚   â”‚   â”œâ”€â”€ tensor.py               # Motor NumPy minimalista
â”‚   â”‚   â””â”€â”€ loss.py                 # MSE / BCE vectorizados
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py             # Componentes cognitivos
â”‚   â”‚   â”œâ”€â”€ memory_cell.py          # Celda de memoria diferenciable
â”‚   â”‚   â”œâ”€â”€ macro_neuron.py         # Macro-neurona con gating
â”‚   â”‚   â”œâ”€â”€ reasoning_unit.py       # Unidad de razonamiento
â”‚   â”‚   â”œâ”€â”€ cognitive_block.py      # Bloque cognitivo modular
â”‚   â”‚   â”œâ”€â”€ cognitive_graph.py      # Grafo de bloques cognitivos
â”‚   â”‚   â”œâ”€â”€ trm_block.py            # Tiny Recursive Model (Fase 10)
â”‚   â”‚   â”œâ”€â”€ trm_act_block.py        # TRM con ACT + deep supervision (Fase 11)
â”‚   â”‚   â”œâ”€â”€ cognitive_graph_trm.py  # Grafo TRM adaptativo (Fase 12)
â”‚   â”‚   â”œâ”€â”€ cognitive_graph_hybrid.py # Grafo hÃ­brido (Fase 13)
â”‚   â”‚   â”œâ”€â”€ projection_layer.py     # AutoAlign (Fase 14)
â”‚   â”‚   â”œâ”€â”€ training/               # Entrenamiento global (Fase 15)
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py         # Alias utilitarios de entrenamiento
â”‚   â”‚   â”‚   â”œâ”€â”€ losses.py           # MSE, L1, BCE vectorizados
â”‚   â”‚   â”‚   â”œâ”€â”€ optimizers.py       # SGD / Adam hÃ­bridos Value-Tensor
â”‚   â”‚   â”‚   â””â”€â”€ trainer.py          # GraphTrainer con deep supervision
â”‚   â”‚   â”œâ”€â”€ attention/              # AtenciÃ³n cognitiva dinÃ¡mica (Fase 16)
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py         # Exportaciones de atenciÃ³n
â”‚   â”‚   â”‚   â”œâ”€â”€ attention_layer.py  # Capa de atenciÃ³n Query-Key-Value
â”‚   â”‚   â”‚   â”œâ”€â”€ attention_router.py # Router de mÃºltiples atenciones
â”‚   â”‚   â”‚   â””â”€â”€ utils.py            # Softmax y utilidades numÃ©ricas
â”‚   â”‚   â””â”€â”€ monitor/                # Cognitive Monitor System (Fase 17)
â”‚   â”‚       â”œâ”€â”€ __init__.py         # Exportaciones de monitoreo
â”‚   â”‚       â”œâ”€â”€ cognitive_monitor.py# Seguimiento de activaciones/atenciÃ³n
â”‚   â”‚       â”œâ”€â”€ logger.py           # Logger JSON/timestamps
â”‚   â”‚       â””â”€â”€ visualizer_streamlit.py # Dashboard interactivo (Fase 19)
â”‚   â”œâ”€â”€ engine/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ trainer.py              # Entrenamiento supervisado
â”‚   â”‚   â”œâ”€â”€ rl_trainer.py           # Entrenamiento RL
â”‚   â”‚   â”œâ”€â”€ dataset.py              # Utilidades de datasets
â”‚   â”‚   â””â”€â”€ predictor.py            # Predictores utilitarios
â”‚   â””â”€â”€ app.py                      # Punto de entrada CLI
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ cognitive_agent_demo.py     # Bloque cognitivo secuencial
â”‚   â”œâ”€â”€ cognitive_graph_demo.py     # Grafo cognitivo (Fase 9)
â”‚   â”œâ”€â”€ trm_demo.py                 # XOR con TRM vectorizado (Fase 10)
â”‚   â”œâ”€â”€ trm_act_demo.py             # TRM con halting adaptativo (Fase 11)
â”‚   â”œâ”€â”€ trm_cognitive_graph_demo.py # Grafo TRM recursivo (Fase 12)
â”‚   â”œâ”€â”€ hybrid_graph_demo.py        # Grafo hÃ­brido TRM + CognitiveBlock (Fase 13)
â”‚   â”œâ”€â”€ hybrid_graph_autoalign_demo.py # AutoAlign dinÃ¡mico (Fase 14)
â”‚   â”œâ”€â”€ global_training_demo.py     # Entrenamiento global con deep supervision (Fase 15)
â”‚   â””â”€â”€ cognitive_attention_demo.py # AtenciÃ³n cognitiva dinÃ¡mica (Fase 16)
â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ app_dashboard.py            # App Streamlit del Cognitive Dashboard (Fase 19)
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_network.py
â”‚   â”œâ”€â”€ test_neuron.py
â”‚   â”œâ”€â”€ test_trainer.py
â”‚   â”œâ”€â”€ test_cognitive_graph_hybrid.py
â”‚   â”œâ”€â”€ test_graph_trainer.py
â”‚   â””â”€â”€ test_attention_router.py    # (Fase 16-17 - futuro)
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ proyecto.md                 # DocumentaciÃ³n general
â”œâ”€â”€ pyproject.toml                  # ConfiguraciÃ³n del proyecto
â””â”€â”€ README.md
```

## ğŸ§© Fases Completadas

### âœ… Fase 1 - Microneuronas y Activaciones
- **Neuronas individuales** con pesos, bias y funciones de activaciÃ³n
- **Funciones de activaciÃ³n**: sigmoid, relu, tanh, linear
- **Derivadas** para backpropagation

### âœ… Fase 2 - Capas y Red Neuronal
- **Capas de neuronas** con conectividad completa
- **Red multicapa** con propagaciÃ³n forward/backward
- **Estructura modular** [inputs, hidden, ..., outputs]

### âœ… Fase 3 - Backpropagation y Trainer
- **Backpropagation completa** desde cero
- **Trainer** para entrenamiento supervisado
- **ValidaciÃ³n de gradientes** y estabilidad

### âœ… Fase 4 - Optimizadores y Estabilidad
- **Optimizadores modulares**: SGD, Momentum, Adam, RMSprop
- **Tests de estabilidad** y validaciÃ³n de backprop
- **ComparaciÃ³n de optimizadores** en ejemplos

### âœ… Fase 5 - Variable Latente z y Proyector
- **Variable latente z** para planificaciÃ³n interna
- **LatentProjector** con proyecciÃ³n lineal + tanh
- **IntegraciÃ³n completa** en NeuralNetwork
- **Ejemplos de entrenamiento** con variable latente

### âœ… Fase 6 - Mini Framework Autograd
- **Motor autograd completo** con propagaciÃ³n automÃ¡tica
- **Nodo Value** con sobrecarga de operadores
- **Operaciones matemÃ¡ticas**: +, -, *, /, tanh, sigmoid, relu
- **API funcional**: linear, mse_loss
- **Entrenamiento XOR** usando autograd sin backprop manual
- **ComparaciÃ³n con backprop manual** validada

### âœ… Fase 7 - Macro-Neuronas Cognitivas
- **Celda de memoria diferenciable** con decaimiento temporal
- **Macro-neurona** que combina input + memoria + gating
- **Razonamiento secuencial** aprendido sin datasets
- **Sistema cognitivo** con contexto temporal
- **Demo de memoria** funcionando con autograd

### âœ… Fase 8 - CognitiveBlock (Arquitectura Cognitiva Modular)
- **ReasoningUnit**: Unidad que combina percepciÃ³n y memoria para inferencias
- **CognitiveBlock**: Bloque cognitivo completo con percepciÃ³n, memoria y razonamiento
- **Arquitectura modular**: Componentes interconectables para construir mentes artificiales
- **Demo de predicciÃ³n secuencial**: Aprende patrones temporales sin supervisiÃ³n
- **IntegraciÃ³n completa**: Todos los componentes usan el motor autograd

### âœ… Fase 9 - CognitiveGraph (Mente Modular Emergente)
- **CognitiveGraph**: Red de CognitiveBlock interconectados
- **ComunicaciÃ³n interbloques**: Feedforward, recurrente y reflexivo
- **Memoria compartida**: Estado global accesible por todos los bloques
- **Demo `cognitive_graph_demo.py`**: Mente artificial con percepciÃ³n â†’ razonamiento â†’ decisiÃ³n
- **Semilla determinista**: `random.seed(42)` para reproducibilidad
- **Alias automÃ¡ticos**: `src/__init__.py` expone `autograd`, `core` y `engine`

### âœ… Fase 10 - Motor Tensor Vectorizado + TRM Base
- **Tensor** NumPy (`core/autograd_numpy`) como reemplazo de `Value` para operaciones vectorizadas
- **Funciones de pÃ©rdida** MSE/BCE adaptadas al nuevo motor
- **TRMBlock** recursivo con estado latente z y detach entre pasos
- **Demo `examples/trm_demo.py`**: TRM aprende XOR con actualizaciÃ³n aproximada

### âœ… Fase 11 - Deep Supervision + Adaptive Computation Time
- **TRM_ACT_Block** con neurona de halting y cÃ¡lculo adaptativo de pasos
- **Deep supervision** en cada iteraciÃ³n con pÃ©rdidas parciales
- **Demo `examples/trm_act_demo.py`** validando razonamiento adaptativo en XOR

### âœ… Fase 12 - CognitiveGraph TRM
- **CognitiveGraphTRM** para orquestar mÃºltiples TRM_ACT conectados
- **Step numÃ©rico** y reset de estados para simulaciones recursivas
- **Demo `examples/trm_cognitive_graph_demo.py`**: pipeline percepciÃ³n â†’ razonamiento â†’ decisiÃ³n
- **Tests `tests/test_trm_cognitive_graph.py`** asegurando estabilidad y resets

### âœ… Fase 13 - CognitiveGraph Hybrid
- **CognitiveGraphHybrid** integra CognitiveBlock clÃ¡sicos y TRM_ACT adaptativos
- **Compatibilidad bidireccional**: convierte salidas entre Value â†” Tensor automÃ¡ticamente
- **Demo `examples/hybrid_graph_demo.py`** demostrando razonamiento mixto
- **Tests `tests/test_cognitive_graph_hybrid.py`** validando reset y estabilidad

### âœ… Fase 14 - AutoAlign Layers
- **ProjectionLayer** genera proyecciones lineales aprendibles entre bloques con dimensiones distintas
- **CognitiveGraphHybrid** ahora crea proyecciones on-the-fly al conectar nodos con tamaÃ±os incompatibles
- **Demo `examples/hybrid_graph_autoalign_demo.py`** muestra conexiones sensor â†’ memory â†’ reasoner â†’ decision con AutoAlign
- **Tests `tests/test_cognitive_graph_hybrid.py`** cubren estabilidad con AutoAlign activado

### âœ… Fase 15 - Deep Supervision Training Loop
- **GraphTrainer** entrena CognitiveGraphHybrid completo con supervisiÃ³n profunda
- **MÃ³dulos `core/training`** centralizan pÃ©rdidas, optimizadores y entrenamiento global
- **Compatibilidad hÃ­brida**: actualiza simultÃ¡neamente CognitiveBlock, TRM_ACT_Block y ProjectionLayer
- **Demo `examples/global_training_demo.py`** aprende XOR extremo a extremo
- **Tests `tests/test_graph_trainer.py`** validan recolecciÃ³n de parÃ¡metros y paso de entrenamiento

### âœ… Fase 16 - Cognitive Attention System (CAS)
- **CognitiveAttentionLayer** calcula atenciÃ³n contextual Query-Key-Value entre bloques
- **AttentionRouter** coordina pesos dinÃ¡micos para cada conexiÃ³n del grafo
- **CognitiveGraphHybrid** integra atenciÃ³n + AutoAlign para foco cognitivo adaptativo
- **Demo `examples/cognitive_attention_demo.py`** muestra cÃ³mo varÃ­a el foco en tiempo real
- **Tests `tests/test_cognitive_graph_hybrid.py`** verifican almacenamiento y normalizaciÃ³n de pesos de atenciÃ³n

### âœ… Fase 17 - Cognitive Monitor System (CMS)
- **CognitiveMonitor** registra activaciones, pesos de atenciÃ³n y pÃ©rdidas en tiempo real
- **CognitiveLogger** provee logging estructurado en consola/JSON con timestamps
- **IntegraciÃ³n** desde CognitiveGraphHybrid y GraphTrainer para telemetrÃ­a continua
- **Demo `examples/cognitive_monitor_demo.py`** ejecuta entrenamiento XOR monitorizado
- **Datos persistentes** listos para dashboards (Streamlit en Fase 19)

### âœ… Fase 18 - Memory Replay System (MRS)
- **EpisodicMemory** almacena inputs, targets, outputs, pÃ©rdidas y mapas de atenciÃ³n
- **MemoryReplaySystem** consolida experiencias exitosas mediante sleep cycles
- **GraphTrainer** registra cada episodio automÃ¡ticamente durante el entrenamiento
- **Fase de sueÃ±o** con `sleep_and_replay()` que reduce la pÃ©rdida promedio
- **Demo `examples/memory_replay_demo.py`** muestra consolidaciÃ³n tras 300 Ã©pocas

### âœ… Fase 19 - Cognitive Dashboard (Streamlit)
- **CognitiveVisualizer** renderiza pÃ©rdidas, activaciones, atenciÃ³n y memoria en tiempo real
- **App Streamlit** `dashboard/app_dashboard.py` consume el grafo activo vÃ­a `st.session_state`
- **IntegraciÃ³n opcional**: demos pueden lanzar el dashboard en segundo plano
- **Dependencias aÃ±adidas**: `streamlit`, `pandas`, `plotly`, `altair`, `pydeck`
- **Interfaz** multipestaÃ±a con mÃ©tricas clave actualizadas durante entrenamiento y sleep cycles

### âœ… Fase 20 - Meta-Learning Loop
- **Paquete `core.meta`** con reglas adaptativas (`adaptive_lr`, `adaptive_focus`, `adaptive_sleep`) que observan pÃ©rdidas y atenciones del monitor
- **MetaLearningController** ajusta dinÃ¡micamente learning rate, foco atencional e intervalo de consolidaciÃ³n usando el monitor y el MemoryReplaySystem
- **Demo `examples/meta_learning_demo.py`** (`PYTHONPATH=src uv run python examples/meta_learning_demo.py`) muestra el bucle autorregulado en acciÃ³n
- **Tests `tests/test_meta_rules.py`** validan las heurÃ­sticas de ajuste
- Detalles ampliados en `docs/fase20_meta_loop.md`

### âœ… Fase 21 - Cognitive Evolution System (CES)
- **Paquete `core.evolution`** con `CognitivePopulation`, utilidades de crossover y el `EvolutionManager` para coordinar generaciones
- **Crossover hÃ­brido** que mezcla pesos tipo Value/Tensor con mutaciones ligeras para mantener diversidad
- **EvoluciÃ³n generacional**: selecciÃ³n de los grafos con mejor fitness, cruce y regeneraciÃ³n automÃ¡tica de la poblaciÃ³n
- **Demo `examples/cognitive_evolution_demo.py`** (`PYTHONPATH=src uv run python examples/cognitive_evolution_demo.py`) ejecuta varias generaciones sobre XOR
- Permite experimentar con evoluciÃ³n de arquitecturas sin alterar el flujo de entrenamiento base

### âœ… Fase 22 - Cognitive Society System (CSS)
- **Paquete `core.society`** con `CognitiveAgent`, `CommunicationChannel` y `SocietyManager` para coordinar agentes mÃºltiples
- **Intercambio social**: agentes comparten experiencias vÃ­a `exchange_memories` y broadcasts de mejores episodios
- **CooperaciÃ³n adaptativa**: cada agente entrena su propio grafo pero se beneficia de memorias ajenas
- **Demo `examples/cognitive_society_demo.py`** (`PYTHONPATH=src uv run python examples/cognitive_society_demo.py`) muestra cÃ³mo convergen las pÃ©rdidas compartiendo conocimiento

### âœ… Fase 23A - Cognitive API Server (CAS)
- **Paquete `api/`** con servidor FastAPI, routers modulares y estado compartido (`CognitiveAppState`)
- **Endpoints REST**: `/predict`, `/feedback`, `/evolve`, `/status` para interactuar con la sociedad en tiempo real
- **IntegraciÃ³n con `.env`**: API key y parÃ¡metros de despliegue para una configuraciÃ³n segura en la Orange Pi
- **Script de arranque** (via `uvicorn src.api.server:app --host 0.0.0.0 --port 8000`), listo para exponerse tras un reverse proxy HTTPS
- **Monitoreo en vivo**: `/status` reporta pÃ©rdidas recientes, memoria y espectro de agentes activos

### âœ… Fase 23B - Cognitive Persistence Layer (CPL)
- **Paquete `core.persistence`** con gestores de rutas, serializaciÃ³n de pesos/memorias y `PersistenceManager`
- **Formato ligero**: pesos en `.npz` comprimido, memorias y mÃ©tricas en `.json` human-readable
- **IntegraciÃ³n con API**: carga automÃ¡tica al iniciar servidor y endpoint `/save` para persistencia manual o vÃ­a cron
- **Directorios `data/persistence/weights|memories`** almacenan hasta 100 episodios recientes por agente
- Asegura continuidad del aprendizaje tras reinicios o despliegues en nodos distribuidos

### âœ… Fase 23C - Cognitive Network (DistribuciÃ³n de Agentes)
- **Paquete `core.distribution`** con `CognitiveDistributor` (cliente HTTP) y helpers de recepciÃ³n
- **Endpoint `/share`** en FastAPI para sincronizar memorias/pesos entre nodos protegidos por API key
- **SerializaciÃ³n remota**: transferencias usan `.npz` base64 y memorias recientes en JSON (lÃ­mite configurable)
- **Tests `tests/test_distribution.py`** validan generaciÃ³n de payload y aplicaciÃ³n remota en entornos aislados
- Permite interconectar Orangeâ€¯Pi, servidores cloud o PCs formando una red de sociedades cognitivas cooperativas

### âœ… Fase 24 - Cognitive Federation (Aprendizaje Federado)
- **Paquete `core.federation`** con utilidades de serializaciÃ³n/promedio y `FederatedClient`
- **Router `/federate`** en FastAPI (servidor cloud) agrega pesos (`/upload`) y entrega promedio global (`/global`)
- **Seguridad**: dependencia `require_api_key` y helper `get_api_headers` reutilizados por distribuidores y clientes
- **Tests `tests/test_federation.py`** cubren serializaciÃ³n, promedio y roundtrip cliente-servidor (requiere FastAPI instalado)
- Permite que nodos locales entrenen con sus datos y sincronicen pesos con un nodo federador sin exponer datos crudos

### âœ… Fase 25 - Cognitive Scheduler (Ciclo AutÃ³nomo)
- **Paquete `core.scheduler`** con `SchedulerConfig` (intervalos/flags) y `CognitiveScheduler` en hilo daemon
- **Ciclos automatizados**: entrenamiento, persistencia, federaciÃ³n opcional, intercambio de memorias y sueÃ±o cognitivo
- **Integrado en `api/dependencies.py`**: se instancia en el arranque, reutilizando `PersistenceManager` y `FederatedClient`
- **ConfiguraciÃ³n flexible** (`loop_sleep`, banderas `enable_*`) permite desactivar federaciÃ³n/evoluciÃ³n en nodos aislados
- DiseÃ±ado para mantener la sociedad aprendiendo sin intervenciÃ³n manual, alineado con despliegues Orangeâ€¯Pi + nube

#### â–¶ï¸ CÃ³mo lanzar el dashboard

1. Inicia el proceso combinado desde la raÃ­z del proyecto:
   ```bash
   PYTHONPATH=src uv run python launch_cognitive.py
   ```
   Este script ejecuta el entrenamiento (demo `memory_replay_demo.py`) y levanta Streamlit en `http://localhost:8501`, persistiendo los snapshots en `dashboard_state.json`.

2. Abre el navegador en `http://localhost:8501` para visualizar las pestaÃ±as de **PÃ©rdidas**, **Activaciones**, **AtenciÃ³n** y **Memoria episÃ³dica**. El dashboard consumirÃ¡ datos en vivo si el entrenamiento sigue corriendo o mostrarÃ¡ el Ãºltimo snapshot disponible.

TambiÃ©n puedes ejecutar los pasos manualmente si prefieres procesos separados:
```bash
# Terminal 1 â€“ entrenamiento
PYTHONPATH=src uv run python examples/memory_replay_demo.py

# Terminal 2 â€“ dashboard
PYTHONPATH=src uv run streamlit run dashboard/app_dashboard.py
``` 
Ambas variantes leen/escriben el snapshot compartido (`dashboard_state.json`), por lo que la visualizaciÃ³n se mantiene incluso cuando el entrenamiento se detiene.




## ğŸ§  Estructura Completa del Proyecto

### ğŸ”§ Componentes Implementados:

#### **Value - Nodo Base**
```python
from autograd.value import Value

# Crear valores con autograd
x = Value(2.0)
y = Value(3.0)
z = x * y + x.relu()  # Operaciones encadenadas
z.backward()  # PropagaciÃ³n automÃ¡tica
print(x.grad)  # Gradiente calculado automÃ¡ticamente
```

#### **Operaciones Disponibles**
- **AritmÃ©ticas**: +, -, *, /, **
- **Activaciones**: tanh, sigmoid, relu, leaky_relu
- **Funciones**: exp, log
- **Red**: linear, mse_loss

#### **Ejemplo de Uso**
```python
# Entrenamiento XOR con autograd
from autograd.value import Value
from autograd.functional import linear, mse_loss

# Crear red con autograd
layer1 = make_layer(2, 4)  # Pesos como Value
layer2 = make_layer(4, 1)

# Forward automÃ¡tico
y_pred = forward(x)
loss = mse_loss(y_pred, y)
loss.backward()  # Â¡Sin backprop manual!
```

### ğŸ¯ Resultados Fase 6:
- **âœ… Motor autograd funcional** sin dependencias
- **âœ… PropagaciÃ³n automÃ¡tica** de gradientes
- **âœ… API intuitiva** estilo PyTorch
- **âœ… Entrenamiento XOR** convergente
- **âœ… ValidaciÃ³n** contra backprop manual

### ğŸ“Š ComparaciÃ³n de Enfoques:
| Enfoque | Backprop | Complejidad | Flexibilidad |
|---------|----------|-------------|--------------|
| Manual  | Manual   | Alta        | Baja         |
| Autograd| AutomÃ¡tica| Baja        | Alta         |

### ğŸš€ PrÃ³ximos Pasos:
- **Fase 10**: Sistemas cognitivos multi-agente
- **VectorizaciÃ³n**: OptimizaciÃ³n con NumPy (opcional)
- **Persistencia**: Guardado/carga de pesos
- **Exportar mÃ¡s alias**: Evaluar exposiciÃ³n plana de `io`, `examples`

## ğŸš€ Uso RÃ¡pido

### Ejemplo BÃ¡sico - XOR
```python
from core.network import NeuralNetwork
from core import losses
from core.optimizers import Adam
from engine.trainer import Trainer

# Dataset XOR
dataset = [
    ([0.0, 0.0], [0.0]),
    ([0.0, 1.0], [1.0]),
    ([1.0, 0.0], [1.0]),
    ([1.0, 1.0], [0.0]),
]

# Crear red
nn = NeuralNetwork([2, 4, 1], activation="sigmoid")

# Entrenar
trainer = Trainer(
    nn,
    loss_fn=losses.mse_loss,
    loss_grad_fn=losses.mse_grad,
    optimizer=Adam(lr=0.01),
    batch_size=1
)

trainer.train(dataset, epochs=2000, verbose=True)
```

### ComparaciÃ³n de Optimizadores
```python
from core.optimizers import SGD, SGDMomentum, Adam, RMSprop

# Probar diferentes optimizadores
optimizers = [
    ("SGD", SGD(lr=0.1)),
    ("Momentum", SGDMomentum(lr=0.05, momentum=0.9)),
    ("Adam", Adam(lr=0.01)),
    ("RMSprop", RMSprop(lr=0.01)),
]

for name, optimizer in optimizers:
    trainer = Trainer(nn, losses.mse_loss, losses.mse_grad, optimizer=optimizer)
    trainer.train(dataset, epochs=1000)
```

## ğŸ§ª EjecuciÃ³n de Tests

### Tests de ValidaciÃ³n
```bash
# Instalar dependencias
uv sync

# Ejecutar todos los tests
uv run python run_tests.py

# Tests individuales
uv run python -m pytest tests/test_stability.py -v
```

### Ejemplos
```bash
# XOR con Adam
uv run python examples/train_xor.py

# Comparar optimizadores
uv run python examples/compare_optimizers.py
```

## ğŸ“Š Arquitectura del Sistema

### Microneurona (Neuron)
```python
class Neuron:
    def __init__(self, n_inputs: int, activation: str = "sigmoid", optimizer: Optimizer = None):
        self.weights: List[float]  # Pesos sinÃ¡pticos
        self.bias: float           # Sesgo
        self.activation: Activation # FunciÃ³n de activaciÃ³n
        self.optimizer: Optimizer   # Optimizador configurable
    
    def forward(self, inputs: List[float]) -> float:
        # PropagaciÃ³n hacia adelante
        pass
    
    def apply_gradients(self, dweights: List[float], dbias: float) -> None:
        # ActualizaciÃ³n con optimizador
        pass
```

### Red Neuronal (NeuralNetwork)
```python
class NeuralNetwork:
    def __init__(self, layer_sizes: List[int], activation: str = "sigmoid"):
        # [n_inputs, n_hidden1, n_hidden2, ..., n_outputs]
        pass
    
    def forward(self, inputs: List[float], z: List[float] = None) -> List[float]:
        # Forward con soporte para variables latentes
        pass
    
    def train_step(self, inputs: List[float], targets: List[float], lr: float) -> float:
        # Un paso completo de entrenamiento
        pass
```

## ğŸ¯ CaracterÃ­sticas Implementadas

### âœ… Funcionalidad Base
- **Redes feedforward** multicapa
- **Backpropagation** completo
- **Funciones de activaciÃ³n** con derivadas
- **Funciones de pÃ©rdida** MSE y BCE
- **OptimizaciÃ³n** con mÃºltiples algoritmos

### âœ… ValidaciÃ³n
- **Tests de estabilidad** con XOR
- **VerificaciÃ³n de convergencia**
- **ValidaciÃ³n numÃ©rica**
- **Sin dependencias externas pesadas**

### âœ… Modularidad
- **Componentes intercambiables**
- **Optimizadores plug-and-play**
- **Funciones de activaciÃ³n extensibles**
- **Tests automatizados**

## ğŸš€ PrÃ³ximos Pasos - Fase 20

### ğŸ§  Memory Replay Dashboard Avanzado
- **Controles interactivos** para filtrar episodios y ajustar replay_factor
- **Comparativa de sesiones** con descargas CSV desde Streamlit

### ğŸ“ˆ Escalabilidad
- **Batch processing** con NumPy para TRM y grafo cognitivo
- **EstadÃ­sticas de halting** y visualizaciÃ³n de pasos de razonamiento
- **Persistencia** de modelos y replay de grafos cognitivos

## ğŸ“‹ Requisitos

- **Python**: >= 3.12
- **Gestor de paquetes**: uv (recomendado)
- **Sistema operativo**: Linux/macOS/Windows

## ğŸ† Logros

- âœ… **0 dependencias pesadas** - Python puro
- âœ… **100% modular** - Cada componente es intercambiable
- âœ… **Tests completos** - ValidaciÃ³n exhaustiva
- âœ… **DocumentaciÃ³n clara** - CÃ³digo educativo
- âœ… **Ejemplos prÃ¡cticos** - XOR y comparaciones

## ğŸ“ PropÃ³sito Educativo

Este proyecto sirve como:
- **Plataforma de aprendizaje** para redes neuronales
- **Base para experimentaciÃ³n** con arquitecturas
- **DemostraciÃ³n** de backpropagation desde cero
- **Puente** hacia frameworks mÃ¡s complejos

---


